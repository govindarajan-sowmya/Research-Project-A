{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xfp8N7IGMvtP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re\n",
        "\n",
        "# Tools for assessing the quality of model prediction\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "# load the dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import re,string,unicodedata\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Hbc9Gpk2D6NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('/content/IMDB Dataset.csv',engine=\"python\",error_bad_lines=False)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "pFkEzWicMwh3",
        "outputId": "6716f174-43a7-41d8-f4c8-72f9aa2dc0cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 22152: unexpected end of data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-74479505-b68d-4271-bf2d-cf44b6f87cff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74479505-b68d-4271-bf2d-cf44b6f87cff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74479505-b68d-4271-bf2d-cf44b6f87cff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74479505-b68d-4271-bf2d-cf44b6f87cff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df['sentiment'].apply(lambda x:1 if x=='negative' else 0)"
      ],
      "metadata": {
        "id": "xU4h1PQ5MwkU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgZwcDO6MwnS",
        "outputId": "4f1e8de0-3893-42a4-d3c6-defa98f0ba18"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review  sentiment\n",
            "0      One of the other reviewers has mentioned that ...          0\n",
            "1      A wonderful little production. <br /><br />The...          0\n",
            "2      I thought this was a wonderful way to spend ti...          0\n",
            "3      Basically there's a family where a little boy ...          1\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...          0\n",
            "...                                                  ...        ...\n",
            "22145  Rich, alcoholic Robert Stack falls in love wit...          0\n",
            "22146  In an era of such awful cartoons, I am rather ...          0\n",
            "22147  Well, at least this was the last sequel that I...          1\n",
            "22148  Oh my God... where to begin? \"Chupacabra Terro...          1\n",
            "22149  This movie is extremely boring, it tells a sto...          1\n",
            "\n",
            "[22150 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization of text\n",
        "tokenizer=ToktokTokenizer()\n",
        "#Setting English stopwords\n",
        "nltk.download('stopwords')\n",
        "stopword_list=nltk.corpus.stopwords.words('english')\n",
        "\n",
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "df['review']=df['review'].apply(denoise_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpMsMLlVMwyz",
        "outputId": "9bcdddf5-c144-4ef6-88c8-923433badf59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oXLRRTDY0G6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for removing special characters\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    return text\n",
        "#function on review column\n",
        "df['review']=df['review'].apply(remove_special_characters)"
      ],
      "metadata": {
        "id": "KMCaxlKcMw1j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set stopwords to english\n",
        "stop=set(stopwords.words('english'))\n",
        "print(stop)\n",
        "\n",
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "#Apply function on review column\n",
        "df['review']=df['review'].apply(remove_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylIaj73qMw4b",
        "outputId": "58f82fb4-e3ee-43f7-8e11-84e9c6cb295d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'wouldn', 'y', 'you', 's', \"didn't\", 'o', 'which', 'themselves', 'doesn', 'yours', \"don't\", 'weren', 'between', 'herself', 'itself', 'a', 'haven', \"it's\", 'as', 'll', 'should', 'i', 'an', 'yourselves', 'nor', 'too', 'both', 'other', \"that'll\", 'there', 'each', \"hadn't\", 'hers', 'being', 'through', 'only', 'under', 'aren', 're', 'them', 'does', 'had', 'when', 'do', 'his', 'himself', 'with', 'no', 'below', 'until', 'have', 'few', \"shan't\", 'him', 'been', 'he', 'to', 'did', 'yourself', 'couldn', \"couldn't\", \"she's\", 'at', 'before', \"won't\", 'in', \"weren't\", \"wasn't\", 'd', \"doesn't\", 'after', 'on', 'from', 'very', \"wouldn't\", 'mustn', 'that', 'these', \"should've\", 'myself', 'shouldn', 'such', 'didn', 'won', 't', 'own', 'out', 'once', 'and', \"shouldn't\", 'during', 'all', 'she', 'so', 'because', 'their', 'again', 'we', \"isn't\", 'down', \"needn't\", 'more', 'who', 'your', 'm', 'theirs', 'some', 'into', 'where', 'or', 'whom', 'was', 'off', 'be', 'any', 'than', 'is', \"haven't\", 'up', 'most', 'my', \"hasn't\", 'same', 'if', 'doing', 'isn', 'then', 'about', 'it', 'will', 'has', 'our', 'the', 'ourselves', 'while', 'were', 'what', 'why', 'this', 'hasn', 'its', 'hadn', 'mightn', \"aren't\", 'how', \"you'll\", \"mustn't\", \"you've\", 'just', 'against', 've', 'over', 'wasn', \"you're\", 'further', 'shan', 'of', 'ma', 'now', 'not', \"mightn't\", 'can', 'ours', 'here', 'having', 'for', 'don', 'am', 'but', 'needn', 'ain', 'by', 'me', 'they', 'are', 'her', \"you'd\", 'those', 'above'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    df = pd.read_csv('/content/IMDB Dataset.csv',engine=\"python\",error_bad_lines=False)\n",
        "    x_data = df['review']       # Reviews/Input\n",
        "    y_data = df['sentiment']    # Sentiment/Output\n",
        "\n",
        "    # PRE-PROCESS REVIEW\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in stop])  # remove stop words\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
        "    \n",
        "    # ENCODE SENTIMENT -> 0 & 1\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_data, y_data = load_dataset()\n",
        "\n",
        "print('Reviews')\n",
        "print(x_data, '\\n')\n",
        "print('Sentiment')\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCDIFVt6SdBK",
        "outputId": "d9dce4bc-a6ad-431d-cde7-be09f22f6203"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 38818: unexpected end of data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews\n",
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [a, wonderful, little, production, the, filmin...\n",
            "2        [i, thought, wonderful, way, spend, time, hot,...\n",
            "3        [basically, family, little, boy, jake, thinks,...\n",
            "4        [petter, mattei, love, time, money, visually, ...\n",
            "                               ...                        \n",
            "38811    [if, ever, watched, dukes, hazard, know, never...\n",
            "38812    [this, film, basically, velvet, goldmine, writ...\n",
            "38813    [the, centerpiece, lackawanna, blues, characte...\n",
            "38814    [i, really, hope, makers, movies, read, review...\n",
            "38815    [this, movie, like, happiness, meets, lost, tr...\n",
            "Name: review, Length: 38816, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "38811    0\n",
            "38812    0\n",
            "38813    1\n",
            "38814    0\n",
            "38815    1\n",
            "Name: sentiment, Length: 38816, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n"
      ],
      "metadata": {
        "id": "SfB-zwmUwEBa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiCLQx8X0MXw",
        "outputId": "493788c6-72b2-4138-8f54-a1ae9071a580"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set\n",
            "13427    [since, i, seen, three, i, figured, i, might, ...\n",
            "25543    [movie, small, town, equal, numbers, mormons, ...\n",
            "13724    [this, movie, really, bad, nothing, appealing,...\n",
            "17006    [i, saw, original, black, white, stars, shelle...\n",
            "32187    [leslie, charteris, series, novels, adventures...\n",
            "                               ...                        \n",
            "31333    [when, attempt, made, assassinate, emir, ohtar...\n",
            "15306    [i, never, expected, old, film, impressive, we...\n",
            "14026    [this, attempt, author, edgar, rice, burroughs...\n",
            "3253     [the, plot, in, mood, love, simple, enough, a,...\n",
            "3964     [beautiful, art, direction, excellent, editing...\n",
            "Name: review, Length: 31052, dtype: object \n",
            "\n",
            "30874    [this, film, provides, us, interesting, remind...\n",
            "17757    [i, got, plus, year, old, computer, games, bet...\n",
            "13261    [i, like, film, i, think, much, book, either, ...\n",
            "14770    [this, film, one, nostalgia, things, i, never,...\n",
            "9460     [critters, this, movie, continued, rd, critter...\n",
            "                               ...                        \n",
            "36765    [tiny, tweet, sly, sneak, locked, cages, train...\n",
            "1958     [about, twenty, minutes, movie, i, already, bo...\n",
            "685      [the, imdb, plot, summary, way, describes, ess...\n",
            "25944    [i, go, game, alright, i, guess, i, expected, ...\n",
            "820      [after, seeing, dick, tracy, bin, future, shop...\n",
            "Name: review, Length: 7764, dtype: object \n",
            "\n",
            "Test Set\n",
            "13427    0\n",
            "25543    0\n",
            "13724    0\n",
            "17006    0\n",
            "32187    1\n",
            "        ..\n",
            "31333    0\n",
            "15306    1\n",
            "14026    0\n",
            "3253     1\n",
            "3964     1\n",
            "Name: sentiment, Length: 31052, dtype: int64 \n",
            "\n",
            "30874    1\n",
            "17757    0\n",
            "13261    0\n",
            "14770    1\n",
            "9460     1\n",
            "        ..\n",
            "36765    1\n",
            "1958     0\n",
            "685      0\n",
            "25944    0\n",
            "820      1\n",
            "Name: sentiment, Length: 7764, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ],
      "metadata": {
        "id": "ASIIQQaJxM7g"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "#Each reviews has a different length, so we need to add padding (by adding 0) or truncating the\n",
        "#words to the same length (in this case, it is the mean of all reviews length) using tensorflow.keras.preprocessing.sequence.pad_sequences.\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "metadata": {
        "id": "nVnjPen8Mw7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a789fd-eca2-4657-98af-3eeccad28e7d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded X Train\n",
            " [[ 135    1   38 ...    1  372  190]\n",
            " [   3  307  401 ...    0    0    0]\n",
            " [   9    3   15 ...    0    0    0]\n",
            " ...\n",
            " [   9  518 1882 ...    0    0    0]\n",
            " [   2   40   49 ...    0    0    0]\n",
            " [ 214  413  373 ...    0    0    0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[   9    4 1525 ...    0    0    0]\n",
            " [   1  102  827 ...    0    0    0]\n",
            " [   1    6    4 ...    0    0    0]\n",
            " ...\n",
            " [   2  704   40 ... 4287 4332    2]\n",
            " [   1   62  357 ...    0    0    0]\n",
            " [ 302  220 1918 ...    0    0    0]] \n",
            "\n",
            "Maximum review length:  130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ARCHITECTURE\n",
        "dim = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(words, dim, input_length = max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3gbqbQvSdEb",
        "outputId": "f82b9295-4db3-454e-ab2f-685cca7148b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 130, 32)           2665408   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                24832     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,690,305\n",
            "Trainable params: 2,690,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = ModelCheckpoint(\n",
        "    'models/imdb.h1',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "_FdlIFo1SdHd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size = 32, epochs = 5, callbacks=[callback])"
      ],
      "metadata": {
        "id": "1A85U8lTSdKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0507c6d-f2ac-4378-c37c-036f78c6d5fe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "971/971 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.7591\n",
            "Epoch 00001: accuracy improved from -inf to 0.75908, saving model to models/imdb.h1\n",
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6861f80> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6861f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6861f80> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6861f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/imdb.h1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/imdb.h1/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f62aba18810> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r971/971 [==============================] - 116s 117ms/step - loss: 0.4811 - accuracy: 0.7591\n",
            "Epoch 2/5\n",
            "971/971 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.9153\n",
            "Epoch 00002: accuracy improved from 0.75908 to 0.91527, saving model to models/imdb.h1\n",
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a657cb00> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a657cb00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a657cb00> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a657cb00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a657cb00> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a657cb00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/imdb.h1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/imdb.h1/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f62aba18810> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r971/971 [==============================] - 114s 117ms/step - loss: 0.2378 - accuracy: 0.9153\n",
            "Epoch 3/5\n",
            "971/971 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9570\n",
            "Epoch 00003: accuracy improved from 0.91527 to 0.95704, saving model to models/imdb.h1\n",
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6663b00> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6663b00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6663b00> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6663b00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6663b00> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a6663b00>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/imdb.h1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/imdb.h1/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f62aba18810> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r971/971 [==============================] - 116s 120ms/step - loss: 0.1399 - accuracy: 0.9570\n",
            "Epoch 4/5\n",
            "971/971 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9675\n",
            "Epoch 00004: accuracy improved from 0.95704 to 0.96747, saving model to models/imdb.h1\n",
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a23730e0> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a23730e0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a23730e0> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a23730e0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a23730e0> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f62a23730e0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/imdb.h1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/imdb.h1/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f62aba18810> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r971/971 [==============================] - 113s 117ms/step - loss: 0.1165 - accuracy: 0.9675\n",
            "Epoch 5/5\n",
            "971/971 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.9045\n",
            "Epoch 00005: accuracy did not improve from 0.96747\n",
            "971/971 [==============================] - 109s 112ms/step - loss: 0.2828 - accuracy: 0.9045\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62a63b9e50>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "scores[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM1iCiho37My",
        "outputId": "4220fb91-d56d-4b8d-ec04-98745326b5a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "243/243 [==============================] - 6s 21ms/step - loss: 0.5844 - accuracy: 0.8026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8025502562522888"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zHZHoxo0TaO",
        "outputId": "d738e7aa-4356-46a9-8d92-98bb6bcd6b62"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_x = model.predict(x_test)\n",
        "classes_x = np.argmax(predict_x,axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "WVzI8M9BXmNd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model('models/imdb.h1')"
      ],
      "metadata": {
        "id": "7FPCJf7JXmXE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = str(input('Movie Review: '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BHKVeVgXmZ9",
        "outputId": "31a9095d-494e-458e-def9-1027f82888de"
      },
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie Review: Nothing was typical about this. Everything was beautifully done in this movie, the story, the flow, the scenario, everything. I highly recommend it for mystery lovers, for anyone who wants to watch a good movie!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regex = re.compile(r'[^a-zA-Z\\s]')\n",
        "review = regex.sub('', review)\n",
        "print('Cleaned: ', review)\n",
        "\n",
        "words = review.split(' ')\n",
        "filtered = [w for w in words if w not in stop]\n",
        "filtered = ' '.join(filtered)\n",
        "filtered = [filtered.lower()]\n",
        "\n",
        "print('Filtered: ', filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1B58KgBXmc2",
        "outputId": "f367a138-a324-4ec1-df02-07f3f7222191"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned:  Nothing was typical about this Everything was beautifully done in this movie the story the flow the scenario everything I highly recommend it for mystery lovers for anyone who wants to watch a good movie\n",
            "Filtered:  ['nothing typical everything beautifully done movie story flow scenario everything i highly recommend mystery lovers anyone wants watch good movie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_words = token.texts_to_sequences(filtered)\n",
        "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
        "print(tokenize_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG1ergC3Xmhd",
        "outputId": "76a9d04c-7270-4e08-8e42-bd1a22770b46"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  78  690  171 1231  127    3   14 2739 2637  171    1  470  278  739\n",
            "  1663  152  392   33    8    3    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = loaded_model.predict(tokenize_words)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWNn1HHfeUUm",
        "outputId": "30249d0f-b5cf-4207-ca8e-2d55c7255069"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99531007]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if result >=0.5 :\n",
        "    print('positive')\n",
        "else:\n",
        "    print('negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS5N6qFAeUXd",
        "outputId": "7241dd57-e889-4b1a-f1af-e6f416efdf22"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    }
  ]
}